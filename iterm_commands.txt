# Check completed count + merge ranking + verify cache (WORKSTATION)

ssh hui@100.66.103.44
cd ~/projects/hui-wang-multi-factor-research

# 1) Progress/complete count (target=18)
find segment_results/stage2_v2026_02_16c_vm_parallel -path "*/segment_summary.csv" | wc -l

# 2) Merge + ranking (value_v2, momentum_v2)
python3 - <<'PY'
from pathlib import Path
import csv, math, statistics

root = Path("segment_results/stage2_v2026_02_16c_vm_parallel")
factors = ["value_v2", "momentum_v2"]
rows_out = []

def to_float(x):
    try:
        v = float(x)
        if math.isnan(v):
            return None
        return v
    except Exception:
        return None

for f in factors:
    files = sorted(root.glob(f"{f}/*/{f}/segment_summary.csv"))
    if not files:
        rows_out.append([f, None, None, None, 0, 0, "NOT_FOUND"])
        continue

    merged = []
    seen = set()
    fieldnames = set()

    for p in files:
        with p.open("r", newline="", encoding="utf-8") as fh:
            r = csv.DictReader(fh)
            if r.fieldnames:
                fieldnames.update(r.fieldnames)
            for row in r:
                key = (row.get("segment_start"), row.get("segment_end"))
                if key in seen:
                    continue
                seen.add(key)
                merged.append(row)

    out_dir = root / "merged" / f
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / "segment_summary.csv"

    fn = list(fieldnames) if fieldnames else []
    with out_path.open("w", newline="", encoding="utf-8") as fh:
        w = csv.DictWriter(fh, fieldnames=fn)
        if fn:
            w.writeheader()
            for row in merged:
                w.writerow({k: row.get(k, "") for k in fn})

    ic_vals = [to_float(r.get("ic")) for r in merged]
    ic_vals = [v for v in ic_vals if v is not None]
    ic_mean = statistics.mean(ic_vals) if ic_vals else None
    ic_std = statistics.stdev(ic_vals) if len(ic_vals) > 1 else None
    pos_ratio = (sum(1 for v in ic_vals if v > 0) / len(ic_vals)) if ic_vals else None

    rows_out.append([f, ic_mean, ic_std, pos_ratio, len(ic_vals), len(merged), f"{len(files)} files merged"])

rows_out.sort(key=lambda x: (x[1] is None, -(x[1] or -1e99)))

print(f"{'factor':>12} {'ic_mean':>10} {'ic_std':>10} {'pos_ratio':>10} {'valid_n':>8} {'rows':>6}  note")
for r in rows_out:
    fm = f"{r[1]:.6f}" if r[1] is not None else "None"
    fs = f"{r[2]:.6f}" if r[2] is not None else "None"
    fp = f"{r[3]:.6f}" if r[3] is not None else "None"
    print(f"{r[0]:>12} {fm:>10} {fs:>10} {fp:>10} {r[4]:>8} {r[5]:>6}  {r[6]}")
PY

# 3) Verify cache files generated (>0 means cache is working)
find cache/stage2_signals_v2026_02_16c_vm -type f | wc -l
